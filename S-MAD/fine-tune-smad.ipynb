{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13988226,"sourceType":"datasetVersion","datasetId":8898060}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport copy\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms   # <-- REQUIRED\nfrom PIL import Image\nimport pandas as pd\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:57:12.935029Z","iopub.execute_input":"2025-12-05T13:57:12.935374Z","iopub.status.idle":"2025-12-05T13:57:12.939728Z","shell.execute_reply.started":"2025-12-05T13:57:12.935337Z","shell.execute_reply":"2025-12-05T13:57:12.938972Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nroot = \"/kaggle/input/face-morph-dsp/FEI_preprocessed/FEI_preprocessed\"\n\nbonafide_dir = os.path.join(root, \"bonafide\")\nmorph_dir = os.path.join(root, \"morphed\")\n\n# Allowed bonafide identity folders\nvalid_ids = {\"5\", \"6\", \"11\", \"12\", \"13\"}\n\nbonafide_rows = []\nmorph_rows = []\n\n# ----------------------------------------------------------\n# PROCESS BONAFIDE (label = 0)\n# ----------------------------------------------------------\nfor fname in os.listdir(bonafide_dir):\n    if not fname.lower().endswith(\".jpg\"):\n        continue\n    \n    # Extract identity: the part before '-'\n    identity = fname.split(\"-\")[0]\n    \n    if identity in valid_ids:\n        bonafide_rows.append({\n            \"path\": os.path.join(bonafide_dir, fname),\n            \"label\": 0\n        })\n\n# ----------------------------------------------------------\n# PROCESS ALL MORPH FILES (label = 1)\n# ----------------------------------------------------------\nfor fname in os.listdir(morph_dir):\n    if not fname.lower().endswith(\".jpg\"):\n        continue\n    \n    morph_rows.append({\n        \"path\": os.path.join(morph_dir, fname),\n        \"label\": 1\n    })\n\n# Convert to DataFrames\nbonafide_df = pd.DataFrame(bonafide_rows)\nmorph_df = pd.DataFrame(morph_rows)\n\n# Optional: merge into 1 file\nfinal_df = pd.concat([bonafide_df, morph_df], ignore_index=True)\nfinal_df.to_csv(\"/kaggle/working/FEI_smad_final.csv\", index=False)\n\nbonafide_df.head(), morph_df.head(), final_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:18.772991Z","iopub.execute_input":"2025-12-05T13:48:18.773385Z","iopub.status.idle":"2025-12-05T13:48:19.001320Z","shell.execute_reply.started":"2025-12-05T13:48:18.773366Z","shell.execute_reply":"2025-12-05T13:48:19.000515Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(                                                path  label\n 0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0,\n                                                 path  label\n 0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1\n 1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1\n 2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1\n 3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1\n 4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1,\n                                                 path  label\n 0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0\n 4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nroot = \"/kaggle/input/face-morph-dsp/FRLL_preprocessed/FRLL_preprocessed\"\n\nbonafide_dir = os.path.join(root, \"FRLL_bonafide\")\nmorph_dir = os.path.join(root, \"morphed\")\n\nbonafide_rows = []\nmorph_rows = []\n\n# ----------------------------------------------------------\n# PROCESS BONAFIDE (label = 0)\n# ----------------------------------------------------------\nfor fname in os.listdir(bonafide_dir):\n    if fname.lower().endswith(\".jpg\"):\n        bonafide_rows.append({\n            \"path\": os.path.join(bonafide_dir, fname),\n            \"label\": 0\n        })\n\n# ----------------------------------------------------------\n# PROCESS MORPH (label = 1)\n# ----------------------------------------------------------\nfor fname in os.listdir(morph_dir):\n    if fname.lower().endswith(\".jpg\"):\n        morph_rows.append({\n            \"path\": os.path.join(morph_dir, fname),\n            \"label\": 1\n        })\n\n# Convert to DataFrames\nbonafide_df = pd.DataFrame(bonafide_rows)\nmorph_df = pd.DataFrame(morph_rows)\n\n# Save separate CSVs\nbonafide_df.to_csv(\"/kaggle/working/FRLL_bonafide_smad.csv\", index=False)\nmorph_df.to_csv(\"/kaggle/working/FRLL_morph_smad.csv\", index=False)\n\n# Combined final dataset\nfinal_df = pd.concat([bonafide_df, morph_df], ignore_index=True)\nfinal_df.to_csv(\"/kaggle/working/FRLL_smad_final.csv\", index=False)\n\nbonafide_df.head(), morph_df.head(), final_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:19.002776Z","iopub.execute_input":"2025-12-05T13:48:19.002993Z","iopub.status.idle":"2025-12-05T13:48:19.130900Z","shell.execute_reply.started":"2025-12-05T13:48:19.002977Z","shell.execute_reply":"2025-12-05T13:48:19.129932Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(                                                path  label\n 0  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 1  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 2  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 3  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 4  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0,\n                                                 path  label\n 0  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      1\n 1  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      1\n 2  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      1\n 3  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      1\n 4  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      1,\n                                                 path  label\n 0  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 1  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 2  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 3  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0\n 4  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# ----------------------------\n# Helper: Extract identity\n# ----------------------------\ndef extract_identity(fname):\n    base = fname.split(\".\")[0]\n    if \"_\" in base:   # FRLL morph e.g. 001_002\n        return base.split(\"_\")[0]\n    if \"-\" in base:   # FEI e.g. 5-01\n        return base.split(\"-\")[0]\n    return base       # FRLL bonafide\n\n# ----------------------------\n# Load FEI + FRLL CSV created earlier\n# ----------------------------\nfei_df = pd.read_csv(\"/kaggle/working/FEI_smad_final.csv\")\nfrll_df = pd.read_csv(\"/kaggle/working/FRLL_smad_final.csv\")\n\n# Combine all\ndf = pd.concat([fei_df, frll_df], ignore_index=True)\n\n# Add identity column\ndf[\"identity\"] = df[\"path\"].apply(lambda x: extract_identity(os.path.basename(x)))\n\n# ----------------------------\n# Group by identity\n# ----------------------------\nidentities = df[\"identity\"].unique()\n\n# Split identities (NOT images)\ntrain_ids, temp_ids = train_test_split(identities, test_size=0.3, random_state=42)\nval_ids, test_ids   = train_test_split(temp_ids, test_size=0.5, random_state=42)\n\n# ----------------------------\n# Assign split based on identity\n# ----------------------------\ntrain_df = df[df[\"identity\"].isin(train_ids)]\nval_df   = df[df[\"identity\"].isin(val_ids)]\ntest_df  = df[df[\"identity\"].isin(test_ids)]\n\n# ----------------------------\n# Save CSVs\n# ----------------------------\ntrain_df.to_csv(\"/kaggle/working/SMAD_train.csv\", index=False)\nval_df.to_csv(\"/kaggle/working/SMAD_val.csv\", index=False)\ntest_df.to_csv(\"/kaggle/working/SMAD_test.csv\", index=False)\n\ntrain_df.head(), val_df.head(), test_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:19.131800Z","iopub.execute_input":"2025-12-05T13:48:19.132077Z","iopub.status.idle":"2025-12-05T13:48:19.747523Z","shell.execute_reply.started":"2025-12-05T13:48:19.132045Z","shell.execute_reply":"2025-12-05T13:48:19.746675Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(                                                path  label identity\n 0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0        6\n 1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0       12\n 2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0        5\n 3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0       13\n 4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0        6,\n                                                   path  label identity\n 85   /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1    42-11\n 89   /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1     1-11\n 91   /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1    31-11\n 92   /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1   197-11\n 130  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1     1-11,\n                                                  path  label identity\n 70  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1   200-11\n 71  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1    28-11\n 72  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1    63-11\n 74  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1   125-11\n 82  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      1   165-11)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# ===============================================================\n# 1. TRANSFORMS\n# ===============================================================\nfrom torchvision import transforms\n\nINPUT_SIZE = 224\nPRE_MEAN = [0.485, 0.456, 0.406]\nPRE_STD  = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(8),\n    transforms.ColorJitter(brightness=0.15, contrast=0.15),\n    transforms.ToTensor(),\n    transforms.Normalize(PRE_MEAN, PRE_STD)\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(PRE_MEAN, PRE_STD)\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:19.748599Z","iopub.execute_input":"2025-12-05T13:48:19.748918Z","iopub.status.idle":"2025-12-05T13:48:19.757918Z","shell.execute_reply.started":"2025-12-05T13:48:19.748888Z","shell.execute_reply":"2025-12-05T13:48:19.756684Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n\nclass SMADDataset(Dataset):\n    def __init__(self, csv_path, transform=None):\n        self.df = pd.read_csv(csv_path)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.iloc[idx][\"path\"]\n        label    = int(self.df.iloc[idx][\"label\"])\n        \n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:19.758887Z","iopub.execute_input":"2025-12-05T13:48:19.759118Z","iopub.status.idle":"2025-12-05T13:48:19.770241Z","shell.execute_reply.started":"2025-12-05T13:48:19.759100Z","shell.execute_reply":"2025-12-05T13:48:19.769453Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ===============================================================\n# LOAD DATASETS FROM CSV (NO IDENTITY LEAKAGE)\n# ===============================================================\n\ntrain_csv = \"/kaggle/working/SMAD_train.csv\"\nval_csv   = \"/kaggle/working/SMAD_val.csv\"\ntest_csv  = \"/kaggle/working/SMAD_test.csv\"\n\ntrain_set = SMADDataset(train_csv, transform=train_transform)\nval_set   = SMADDataset(val_csv,   transform=val_transform)\ntest_set  = SMADDataset(test_csv,  transform=val_transform)\n\ntrain_loader = DataLoader(train_set, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_set,   batch_size=16, shuffle=False)\ntest_loader  = DataLoader(test_set,  batch_size=16, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:48:19.772981Z","iopub.execute_input":"2025-12-05T13:48:19.773300Z","iopub.status.idle":"2025-12-05T13:48:19.808447Z","shell.execute_reply.started":"2025-12-05T13:48:19.773276Z","shell.execute_reply":"2025-12-05T13:48:19.807786Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# ===============================================================\n# 3. LOAD PRETRAINED EFFICIENTNET-B3\n# ===============================================================\nfrom torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n\nmodel = efficientnet_b3(weights=None)\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n\ncheckpoint_path = \"/kaggle/input/face-morph-dsp/efficientnet_b3_morphing.pth\"\nstate = torch.load(checkpoint_path, map_location=\"cpu\")\nmodel.load_state_dict(state)\nprint(\"Loaded pretrained S-MAD EfficientNet-B3\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:53:12.985300Z","iopub.execute_input":"2025-12-05T13:53:12.985912Z","iopub.status.idle":"2025-12-05T13:53:13.926349Z","shell.execute_reply.started":"2025-12-05T13:53:12.985889Z","shell.execute_reply":"2025-12-05T13:53:13.925567Z"}},"outputs":[{"name":"stdout","text":"Loaded pretrained S-MAD EfficientNet-B3\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ===============================================================\n# 4. FREEZE 90% OF LAYERS (SAFE FINE-TUNE)\n# ===============================================================\n\nfor name, param in model.named_parameters():\n    if \"blocks.5\" not in name and \"blocks.6\" not in name and \"classifier\" not in name:\n        param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:53:22.705929Z","iopub.execute_input":"2025-12-05T13:53:22.706509Z","iopub.status.idle":"2025-12-05T13:53:22.711740Z","shell.execute_reply.started":"2025-12-05T13:53:22.706484Z","shell.execute_reply":"2025-12-05T13:53:22.710982Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n# ===============================================================\n# 5. OPTIMIZER & LOSS\n# ===============================================================\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n                       lr=1e-5, weight_decay=1e-4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:53:24.180957Z","iopub.execute_input":"2025-12-05T13:53:24.181666Z","iopub.status.idle":"2025-12-05T13:53:24.186919Z","shell.execute_reply.started":"2025-12-05T13:53:24.181642Z","shell.execute_reply":"2025-12-05T13:53:24.186361Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ===============================================================\n# SAVE DIRECTORY + TIMESTAMP\n# ===============================================================\nimport os\nfrom datetime import datetime\n\nsave_dir = \"checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n# ===============================================================\n# TRAINING LOOP\n# ===============================================================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nbest_acc = 0.0\nbest_wts = copy.deepcopy(model.state_dict())\n\ndef train_model(model, epochs=8):\n    global best_acc, best_wts, timestamp\n    \n    for epoch in range(epochs):\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(\"-\" * 50)\n\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n\n        for imgs, labels in train_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            _, preds = torch.max(outputs, 1)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * imgs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        train_loss = running_loss / len(train_set)\n        train_acc = running_corrects.double() / len(train_set)\n\n        # ----------------------------\n        # VALIDATION\n        # ----------------------------\n        model.eval()\n        val_loss = 0.0\n        val_corrects = 0\n\n        with torch.no_grad():\n            for imgs, labels in val_loader:\n                imgs, labels = imgs.to(device), labels.to(device)\n                outputs = model(imgs)\n                loss = criterion(outputs, labels)\n\n                _, preds = torch.max(outputs, 1)\n                val_loss += loss.item() * imgs.size(0)\n                val_corrects += torch.sum(preds == labels.data)\n\n        val_loss = val_loss / len(val_set)\n        val_acc = val_corrects.double() / len(val_set)\n\n        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n        print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n\n        # ----------------------------\n        # SAVE BEST MODEL SAFELY\n        # ----------------------------\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_wts = copy.deepcopy(model.state_dict())\n\n            save_path = f\"{save_dir}/efficientnet_smad_finetuned_{timestamp}.pth\"\n            torch.save(best_wts, save_path)\n\n            print(f\"ðŸ’¾ Saved best fine-tuned model â†’ {save_path}\")\n\n    model.load_state_dict(best_wts)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:57:17.934182Z","iopub.execute_input":"2025-12-05T13:57:17.934869Z","iopub.status.idle":"2025-12-05T13:57:17.988088Z","shell.execute_reply.started":"2025-12-05T13:57:17.934844Z","shell.execute_reply":"2025-12-05T13:57:17.987523Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n\n# ===============================================================\n# 7. RUN TRAINING\n# ===============================================================\n\nmodel = train_model(model, epochs=8)\nprint(\"Fine-tuning complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T13:57:20.502973Z","iopub.execute_input":"2025-12-05T13:57:20.503607Z","iopub.status.idle":"2025-12-05T14:18:48.273142Z","shell.execute_reply.started":"2025-12-05T13:57:20.503587Z","shell.execute_reply":"2025-12-05T14:18:48.272478Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/8\n--------------------------------------------------\nTrain Loss: 0.5002 | Train Acc: 0.8616\nVal   Loss: 0.3153 | Val   Acc: 0.8956\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 2/8\n--------------------------------------------------\nTrain Loss: 0.4203 | Train Acc: 0.8753\nVal   Loss: 0.2779 | Val   Acc: 0.9052\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 3/8\n--------------------------------------------------\nTrain Loss: 0.3582 | Train Acc: 0.8883\nVal   Loss: 0.1968 | Val   Acc: 0.9193\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 4/8\n--------------------------------------------------\nTrain Loss: 0.3134 | Train Acc: 0.8960\nVal   Loss: 0.1202 | Val   Acc: 0.9459\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 5/8\n--------------------------------------------------\nTrain Loss: 0.2514 | Train Acc: 0.9084\nVal   Loss: 0.1346 | Val   Acc: 0.9400\n\nEpoch 6/8\n--------------------------------------------------\nTrain Loss: 0.2284 | Train Acc: 0.9154\nVal   Loss: 0.0985 | Val   Acc: 0.9578\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 7/8\n--------------------------------------------------\nTrain Loss: 0.2049 | Train Acc: 0.9204\nVal   Loss: 0.0755 | Val   Acc: 0.9726\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\n\nEpoch 8/8\n--------------------------------------------------\nTrain Loss: 0.2045 | Train Acc: 0.9268\nVal   Loss: 0.0808 | Val   Acc: 0.9748\nðŸ’¾ Saved best fine-tuned model â†’ checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\nFine-tuning complete.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import shutil\n\nsrc = \"checkpoints/efficientnet_smad_finetuned_20251205_135717.pth\"\ndst = \"efficientnet_smad_finetuned_backup.pth\"\n\nshutil.copy(src, dst)\nprint(\"Duplicated:\", dst)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:26:32.185511Z","iopub.execute_input":"2025-12-05T14:26:32.185789Z","iopub.status.idle":"2025-12-05T14:26:32.216354Z","shell.execute_reply.started":"2025-12-05T14:26:32.185769Z","shell.execute_reply":"2025-12-05T14:26:32.215723Z"}},"outputs":[{"name":"stdout","text":"Duplicated: efficientnet_smad_finetuned_backup.pth\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:27:41.493086Z","iopub.execute_input":"2025-12-05T14:27:41.493711Z","iopub.status.idle":"2025-12-05T14:27:41.497581Z","shell.execute_reply.started":"2025-12-05T14:27:41.493687Z","shell.execute_reply":"2025-12-05T14:27:41.496824Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# -------------------------------------------------------\n# 3. Load Test Dataset\n# -------------------------------------------------------\ntest_csv = \"/kaggle/working/SMAD_test.csv\"\ntest_set = SMADDataset(test_csv, transform=test_transform)\ntest_loader = DataLoader(test_set, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:28:18.195985Z","iopub.execute_input":"2025-12-05T14:28:18.196270Z","iopub.status.idle":"2025-12-05T14:28:18.204589Z","shell.execute_reply.started":"2025-12-05T14:28:18.196249Z","shell.execute_reply":"2025-12-05T14:28:18.203978Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"\n# -------------------------------------------------------\n# 4. Load Your Fine-Tuned EfficientNet-B3\n# -------------------------------------------------------\nfrom torchvision.models import efficientnet_b3\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = efficientnet_b3(weights=None)\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n\npth_path = \"/kaggle/working/efficientnet_smad_finetuned_backup.pth\"   # <== PUT YOUR PTH FILE HERE\n\nstate = torch.load(pth_path, map_location=device)\nmodel.load_state_dict(state)\nmodel = model.to(device)\n\nmodel.eval()\nprint(\"Loaded model for testing:\", pth_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:28:46.431033Z","iopub.execute_input":"2025-12-05T14:28:46.431637Z","iopub.status.idle":"2025-12-05T14:28:46.816890Z","shell.execute_reply.started":"2025-12-05T14:28:46.431613Z","shell.execute_reply":"2025-12-05T14:28:46.816179Z"}},"outputs":[{"name":"stdout","text":"Loaded model for testing: /kaggle/working/efficientnet_smad_finetuned_backup.pth\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# -------------------------------------------------------\n# 5. Run Testing\n# -------------------------------------------------------\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for imgs, labels in test_loader:\n        imgs, labels = imgs.to(device), labels.to(device)\n\n        outputs = model(imgs)\n        _, preds = torch.max(outputs, 1)\n\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\ntest_acc = correct / total\nprint(f\"\\nðŸŽ¯ FINAL TEST ACCURACY: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:28:49.218886Z","iopub.execute_input":"2025-12-05T14:28:49.219495Z","iopub.status.idle":"2025-12-05T14:29:33.335004Z","shell.execute_reply.started":"2025-12-05T14:28:49.219471Z","shell.execute_reply":"2025-12-05T14:29:33.334162Z"}},"outputs":[{"name":"stdout","text":"\nðŸŽ¯ FINAL TEST ACCURACY: 0.9715\n","output_type":"stream"}],"execution_count":26}]}