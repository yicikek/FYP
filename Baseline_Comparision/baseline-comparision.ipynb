{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":13967604,"datasetId":8898060,"databundleVersionId":14741356}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load File\n","metadata":{}},{"cell_type":"code","source":"import os\nimport itertools\n\n# ------------------------\n# Folder and output paths\n# ------------------------\nbonafide_dir = \"/kaggle/input/face-morph-dsp/FRLL_preprocessed/FRLL_preprocessed/bonafide\"\noutput_file  = \"/kaggle/working/FRLL_bonafide.txt\"\n\n\n# Only include selected codes (you can adjust if needed)\nvalid_codes = {\"02\",\"03\",\"04\",\"07\",\"09\", \"08\"}\n\n# ------------------------\n# List all JPG files\n# ------------------------\nbonafide_files = sorted([f for f in os.listdir(bonafide_dir) if f.lower().endswith(\".jpg\")])\n\nprint(\"Total bonafide images:\", len(bonafide_files))\nprint(\"Sample files:\", bonafide_files[:6])\n\n# ------------------------\n# Group by person (before '_') and filter by code (after '_')\n# ------------------------\ngrouped = {}\nfor f in bonafide_files:\n    if \"_\" in f:\n        person_id, code = f.split(\"_\")\n        code = code.split(\".\")[0]  # remove .jpg\n        if code in valid_codes:\n            grouped.setdefault(person_id, []).append(f)\n\n# ------------------------\n# Generate all combinations within same person\n# ------------------------\npairs = []\nfor person, files in grouped.items():\n    if len(files) >= 2:\n        for a, b in itertools.combinations(files, 2):\n            pairs.append(f\"{a} {b}\")\n\n# ------------------------\n# Save pairs to file\n# ------------------------\nwith open(output_file, \"w\") as f:\n    f.write(\"\\n\".join(pairs))\n\nprint(f\"âœ… Done! Created bonafide_pairs.txt with {len(pairs)} pairs.\")\nprint(f\"ðŸ“„ Saved to: {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:23.572822Z","iopub.execute_input":"2025-12-04T03:02:23.573470Z","iopub.status.idle":"2025-12-04T03:02:23.598230Z","shell.execute_reply.started":"2025-12-04T03:02:23.573445Z","shell.execute_reply":"2025-12-04T03:02:23.597551Z"}},"outputs":[{"name":"stdout","text":"Total bonafide images: 612\nSample files: ['001_02.jpg', '001_03.jpg', '001_04.jpg', '001_07.jpg', '001_08.jpg', '001_09.jpg']\nâœ… Done! Created bonafide_pairs.txt with 1530 pairs.\nðŸ“„ Saved to: /kaggle/working/FRLL_bonafide.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport itertools\n\n# Folder containing all images like 1-01.jpg, 1-02.jpg, etc.\nbonafide_dir = \"/kaggle/input/face-morph-dsp/FEI_preprocessed/FEI_preprocessed/bonafide\"\n\n# Output file\nbonafide_pairs_file = \"/kaggle/working/FEI_bonafide.txt\"\n\n# Only use these emotion/angle codes\nvalid_codes = {\"04\", \"05\", \"06\", \"07\", \"11\", \"12\", \"13\"}\n\n# List only JPG files\nbonafide_files = sorted([f for f in os.listdir(bonafide_dir) if f.lower().endswith(\".jpg\")])\n\n# Group images by person number (before the \"-\")\ngrouped = {}\nfor f in bonafide_files:\n    if \"-\" in f:\n        person_id, code = f.split(\"-\")\n        code = code.split(\".\")[0]  # remove .jpg\n        if code in valid_codes:\n            grouped.setdefault(person_id, []).append(f)\n\n# Create bonafide-bonafide pairs (within same person)\nbonafide_pairs = []\nfor person, files in grouped.items():\n    if len(files) >= 2:\n        # make all unique pairs (e.g., 03-04, 03-05, etc.)\n        for a, b in itertools.combinations(files, 2):\n            bonafide_pairs.append(f\"{a} {b}\")\n\n# Save to file\nwith open(bonafide_pairs_file, \"w\") as f:\n    f.write(\"\\n\".join(bonafide_pairs))\n\nprint(f\"âœ… Done! Created bonafide_pairs.txt with {len(bonafide_pairs)} pairs.\")\nprint(f\"ðŸ“„ Saved to: {bonafide_pairs_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:23.599991Z","iopub.execute_input":"2025-12-04T03:02:23.600300Z","iopub.status.idle":"2025-12-04T03:02:23.636339Z","shell.execute_reply.started":"2025-12-04T03:02:23.600274Z","shell.execute_reply":"2025-12-04T03:02:23.635788Z"}},"outputs":[{"name":"stdout","text":"âœ… Done! Created bonafide_pairs.txt with 4200 pairs.\nðŸ“„ Saved to: /kaggle/working/FEI_bonafide.txt\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:23.636930Z","iopub.execute_input":"2025-12-04T03:02:23.637152Z","iopub.status.idle":"2025-12-04T03:02:25.313663Z","shell.execute_reply.started":"2025-12-04T03:02:23.637135Z","shell.execute_reply":"2025-12-04T03:02:25.312734Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\n# ==================================================\n# 1. LOAD BONAFIDE PAIRS FROM TXT FILE\n# ==================================================\ndef load_bonafide_pairs(txt_path):\n    pairs = []\n    with open(txt_path, \"r\") as f:\n        for line in f:\n            parts = line.strip().split()\n            if len(parts) != 2:\n                continue\n            a, b = parts\n            pairs.append((a, b, 0))  # label = 0\n    return pairs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:25.314554Z","iopub.execute_input":"2025-12-04T03:02:25.315029Z","iopub.status.idle":"2025-12-04T03:02:25.320055Z","shell.execute_reply.started":"2025-12-04T03:02:25.315004Z","shell.execute_reply":"2025-12-04T03:02:25.319366Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# ==================================================\n# 2. FEI: BONAFIDE FROM TXT + ORIGINAL WORKING MORPH CODE\n# ==================================================\ndef create_dmad_labels_fei(base_dir, txt_path):\n    bona_dir  = os.path.join(base_dir, \"bonafide\")\n    morph_dir = os.path.join(base_dir, \"morphed\")\n    out_csv   = \"/kaggle/working/FEI_dmad_labels.csv\"\n\n    records = []\n\n    # ------------------ BONAFIDE FROM TEXT FILE ------------------\n    bonafide_pairs = load_bonafide_pairs(txt_path)\n\n    for a, b, lbl in bonafide_pairs:\n        img1 = os.path.join(bona_dir, a)\n        img2 = os.path.join(bona_dir, b)\n        records.append([img1.replace(\"\\\\\",\"/\"),\n                        img2.replace(\"\\\\\",\"/\"),\n                        0])\n\n    # ------------------ MORPH (ORIGINAL SUCCESSFUL CODE) ------------------\n    morph_files = sorted(os.listdir(morph_dir))\n\n    for f in morph_files:\n        if not f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            continue\n\n        base = os.path.splitext(f)[0]     # e.g. 43-11_99-11_1\n        id1  = base.split(\"_\")[0]         # â†’ 43-11\n\n        bona_path = os.path.join(bona_dir, f\"{id1}.jpg\")\n        morph_path = os.path.join(morph_dir, f)\n\n        if os.path.exists(bona_path):  # âœ” ORIGINAL CHECK\n            records.append([\n                bona_path.replace(\"\\\\\",\"/\"),\n                morph_path.replace(\"\\\\\",\"/\"),\n                1\n            ])\n\n    df = pd.DataFrame(records, columns=[\"image1\",\"image2\",\"label\"])\n    df.to_csv(out_csv, index=False)\n\n    print(\"\\nðŸ”¥ FEI labeling complete â†’\", out_csv)\n    print(\"Bonafide:\", (df.label==0).sum())\n    print(\"Morph:\", (df.label==1).sum())\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:25.322379Z","iopub.execute_input":"2025-12-04T03:02:25.322615Z","iopub.status.idle":"2025-12-04T03:02:25.340206Z","shell.execute_reply.started":"2025-12-04T03:02:25.322599Z","shell.execute_reply":"2025-12-04T03:02:25.339623Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# ==================================================\n# 3. FRLL: BONAFIDE FROM TXT + ORIGINAL WORKING MORPH CODE\n# ==================================================\ndef create_dmad_labels_frll(base_dir, txt_path):\n    bona_dir  = os.path.join(base_dir, \"bonafide\")\n    bona_dir2  = os.path.join(base_dir, \"FRLL_bonafide\")\n    morph_dir = os.path.join(base_dir, \"morphed\")\n    out_csv   = \"/kaggle/working/FRLL_dmad_labels.csv\"\n\n    records = []\n\n    # ------------------ BONAFIDE FROM TEXT FILE ------------------\n    bonafide_pairs = load_bonafide_pairs(txt_path)\n\n    for a, b, lbl in bonafide_pairs:\n        img1 = os.path.join(bona_dir, a)\n        img2 = os.path.join(bona_dir, b)\n        records.append([img1.replace(\"\\\\\",\"/\"),\n                        img2.replace(\"\\\\\",\"/\"),\n                        0])\n\n    # ------------------ MORPH (ORIGINAL SUCCESSFUL CODE) ------------------\n    morph_files = sorted(os.listdir(morph_dir))\n\n    for f in morph_files:\n        if not f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n            continue\n\n        base = os.path.splitext(f)[0]    # e.g. 173_03-142_03_1\n        id1  = base.split(\"-\")[0]        # â†’ 173_03\n\n        bona_path = os.path.join(bona_dir2, f\"{id1}.jpg\")\n        morph_path = os.path.join(morph_dir, f)\n\n        if os.path.exists(bona_path):  # âœ” ORIGINAL CHECK\n            records.append([\n                bona_path.replace(\"\\\\\",\"/\"),\n                morph_path.replace(\"\\\\\",\"/\"),\n                1\n            ])\n\n    df = pd.DataFrame(records, columns=[\"image1\",\"image2\",\"label\"])\n    df.to_csv(out_csv, index=False)\n\n    print(\"\\nðŸ”¥ FRLL labeling complete â†’\", out_csv)\n    print(\"Bonafide:\", (df.label==0).sum())\n    print(\"Morph:\", (df.label==1).sum())\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:25.340896Z","iopub.execute_input":"2025-12-04T03:02:25.341111Z","iopub.status.idle":"2025-12-04T03:02:25.359595Z","shell.execute_reply.started":"2025-12-04T03:02:25.341088Z","shell.execute_reply":"2025-12-04T03:02:25.359010Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ==================================================\n# 4. RUN BOTH + COMBINE\n# ==================================================\nBASE_FEI  = \"/kaggle/input/face-morph-dsp/FEI_preprocessed/FEI_preprocessed\"\nBASE_FRLL = \"/kaggle/input/face-morph-dsp/FRLL_preprocessed/FRLL_preprocessed\"\n\nTXT_FEI   = \"/kaggle/working/FEI_bonafide.txt\"\nTXT_FRLL  = \"/kaggle/working/FRLL_bonafide.txt\"\n\n# Ensure output directory exists\nos.makedirs(\"dataset_info\", exist_ok=True)\n\nfei_df  = create_dmad_labels_fei(BASE_FEI, TXT_FEI)\nfrll_df = create_dmad_labels_frll(BASE_FRLL, TXT_FRLL)\n\n# Combine\ncombined = pd.concat([fei_df, frll_df], ignore_index=True)\ncombined.to_csv(\"/kaggle/working/combined_dmad_labels.csv\", index=False)\n\nprint(\"\\nðŸ”¥ Combined dataset created â†’ dataset_info/combined_dmad_labels.csv\")\nprint(\"Total pairs:\", len(combined))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:25.360236Z","iopub.execute_input":"2025-12-04T03:02:25.360514Z","iopub.status.idle":"2025-12-04T03:02:25.836625Z","shell.execute_reply.started":"2025-12-04T03:02:25.360497Z","shell.execute_reply":"2025-12-04T03:02:25.835997Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¥ FEI labeling complete â†’ /kaggle/working/FEI_dmad_labels.csv\nBonafide: 4200\nMorph: 6000\n\nðŸ”¥ FRLL labeling complete â†’ /kaggle/working/FRLL_dmad_labels.csv\nBonafide: 1530\nMorph: 2175\n\nðŸ”¥ Combined dataset created â†’ dataset_info/combined_dmad_labels.csv\nTotal pairs: 13905\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Start\n","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\n\nclass DMADDatasetByIndex(Dataset):\n    def __init__(self, csv_path, img1_idx, img2_idx, label_idx, transform=None, has_header=True):\n        # If your file has a header row like: img1,img2,label\n        if has_header:\n            self.df = pd.read_csv(csv_path)          # header = first row\n        else:\n            self.df = pd.read_csv(csv_path, header=None)\n\n        print(\"CSV shape:\", self.df.shape)\n        print(self.df.head())  # debug\n\n        self.img1_idx = img1_idx\n        self.img2_idx = img2_idx\n        self.label_idx = label_idx\n        self.transform = transform\n\n        # If labels are in a string column name, we will handle it in __getitem__\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n\n        # Access by index\n        img1_path = row.iloc[self.img1_idx]\n        img2_path = row.iloc[self.img2_idx]\n        raw_label = row.iloc[self.label_idx]\n\n        # Handle label safely\n        # Case 1: already numeric or string number like \"0\"/\"1\"\n        try:\n            label = int(raw_label)\n        except ValueError:\n            # Case 2: text label, map manually\n            # Adjust mapping if your file uses different words\n            if str(raw_label).lower() in [\"bonafide\", \"genuine\", \"real\"]:\n                label = 0\n            elif str(raw_label).lower() in [\"morph\", \"attack\", \"fake\"]:\n                label = 1\n            else:\n                raise ValueError(f\"Unexpected label value: {raw_label}\")\n\n        img1 = Image.open(img1_path).convert(\"RGB\")\n        img2 = Image.open(img2_path).convert(\"RGB\")\n\n        if self.transform:\n            img1 = self.transform(img1)\n            img2 = self.transform(img2)\n\n        return img1, img2, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:25.837349Z","iopub.execute_input":"2025-12-04T03:02:25.837604Z","iopub.status.idle":"2025-12-04T03:02:29.495324Z","shell.execute_reply.started":"2025-12-04T03:02:25.837575Z","shell.execute_reply":"2025-12-04T03:02:29.494662Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/working/FEI_dmad_labels.csv\")\nprint(df.columns)\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:29.496039Z","iopub.execute_input":"2025-12-04T03:02:29.496447Z","iopub.status.idle":"2025-12-04T03:02:29.527392Z","shell.execute_reply.started":"2025-12-04T03:02:29.496417Z","shell.execute_reply":"2025-12-04T03:02:29.526808Z"}},"outputs":[{"name":"stdout","text":"Index(['image1', 'image2', 'label'], dtype='object')\n                                              image1  \\\n0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n\n                                              image2  label  \n0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# ðŸ“Œ 2. Cosine Evaluation Function (Used for ALL Baselines)\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch.nn.functional as F\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.metrics import roc_curve\n\ndef evaluate_cosine_full(model, dataloader, device):\n    model.eval()\n    all_scores, all_labels = [], []\n\n    with torch.no_grad():\n        for img1, img2, labels in dataloader:\n            img1 = img1.to(device)\n            img2 = img2.to(device)\n\n            labels = labels.cpu().numpy()\n\n            emb1 = model(img1)\n            emb2 = model(img2)\n\n            cos = F.cosine_similarity(emb1, emb2, dim=1).cpu().numpy()\n\n            all_scores.extend(list(cos))\n            all_labels.extend(list(labels))\n\n    all_scores = np.array(all_scores)\n    all_labels = np.array(all_labels)\n\n    # ------------------------------------------------------\n    # ðŸ”¥ Best Threshold (sweeping)\n    # ------------------------------------------------------\n    best_acc = 0\n    best_t = 0\n\n    for t in np.linspace(-1, 1, 400):\n        preds = (all_scores < t).astype(int)   # morph = 1\n        acc = (preds == all_labels).mean()\n        if acc > best_acc:\n            best_acc = acc\n            best_t = t\n\n    # Apply the best threshold\n    preds = (all_scores < best_t).astype(int)\n\n    # ------------------------------------------------------\n    # ðŸ”¥ Metrics\n    # ------------------------------------------------------\n    precision = precision_score(all_labels, preds, zero_division=0)\n    recall = recall_score(all_labels, preds, zero_division=0)\n    f1 = f1_score(all_labels, preds, zero_division=0)\n    roc_auc = roc_auc_score(all_labels, all_scores)\n\n    # ------------------------------------------------------\n    # ðŸ”¥ FAR / FRR / EER\n    # ------------------------------------------------------\n    fpr, tpr, thresholds = roc_curve(all_labels, -all_scores)  # invert for morph=1\n    fnr = 1 - tpr\n    eer_index = np.nanargmin(np.abs(fnr - fpr))\n    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n\n    FAR = fpr[eer_index]\n    FRR = fnr[eer_index]\n\n    # ------------------------------------------------------\n    # ðŸ”¥ Avg Cosines\n    # ------------------------------------------------------\n    bona_cos = all_scores[all_labels == 0].mean()\n    morph_cos = all_scores[all_labels == 1].mean()\n\n    # ------------------------------------------------------\n    # ðŸ”¥ Print Final Results (same format as your FYP model)\n    # ------------------------------------------------------\n    print(\"\\n==================== COSINE BASELINE RESULTS ====================\")\n    print(f\"Best Threshold:          {best_t:.4f}\")\n    print(f\"Accuracy:                {best_acc * 100:.2f}%\")\n    print(f\"Precision:               {precision:.4f}\")\n    print(f\"Recall:                  {recall:.4f}\")\n    print(f\"F1-Score:                {f1:.4f}\")\n    print(f\"ROC-AUC:                 {roc_auc:.4f}\")\n    print(f\"FAR:                     {FAR:.4f}\")\n    print(f\"FRR:                     {FRR:.4f}\")\n    print(f\"EER:                     {eer:.4f}\")\n    print(f\"Avg Bona Cosine:         {bona_cos:.4f}\")\n    print(f\"Avg Morph Cosine:        {morph_cos:.4f}\")\n    print(\"===============================================================\\n\")\n\n    return {\n        \"threshold\": best_t,\n        \"accuracy\": best_acc,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n        \"roc_auc\": roc_auc,\n        \"far\": FAR,\n        \"frr\": FRR,\n        \"eer\": eer,\n        \"bona_cos\": bona_cos,\n        \"morph_cos\": morph_cos,\n        \"all_scores\": all_scores,\n        \"all_labels\": all_labels\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:29.528096Z","iopub.execute_input":"2025-12-04T03:02:29.528367Z","iopub.status.idle":"2025-12-04T03:02:30.168127Z","shell.execute_reply.started":"2025-12-04T03:02:29.528345Z","shell.execute_reply":"2025-12-04T03:02:30.167573Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# BASELINE 1: SIMPLE SIAMESE\n1. Define a Simple Siamese Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\nclass SimpleSiamese(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1,1)),\n        )\n        self.fc = nn.Linear(64, 128)\n\n    def forward_once(self, x):\n        x = self.encoder(x)\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\n    def forward(self, img1, img2):\n        emb1 = self.forward_once(img1)\n        emb2 = self.forward_once(img2)\n        return emb1, emb2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.168857Z","iopub.execute_input":"2025-12-04T03:02:30.169319Z","iopub.status.idle":"2025-12-04T03:02:30.174858Z","shell.execute_reply.started":"2025-12-04T03:02:30.169294Z","shell.execute_reply":"2025-12-04T03:02:30.174087Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"2. Contrastive Loss","metadata":{}},{"cell_type":"code","source":"def contrastive_loss(emb1, emb2, label, margin=1.0):\n    dist = F.pairwise_distance(emb1, emb2)\n    loss = (1 - label) * dist.pow(2) + label * F.relu(margin - dist).pow(2)\n    return loss.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.175731Z","iopub.execute_input":"2025-12-04T03:02:30.176064Z","iopub.status.idle":"2025-12-04T03:02:30.192998Z","shell.execute_reply.started":"2025-12-04T03:02:30.176046Z","shell.execute_reply":"2025-12-04T03:02:30.192219Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"3. Train Siamese on FEI","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef train_siamese(model, loader, device, epochs=5, margin=1.0):\n    model.to(device)\n    optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0.0\n        total_correct = 0\n        total_samples = 0\n\n        for img1, img2, labels in loader:\n            img1 = img1.to(device)\n            img2 = img2.to(device)\n            labels = labels.float().to(device)   # 0 = same/bona, 1 = morph/attack\n\n            # --- forward ---\n            emb1, emb2 = model(img1, img2)\n\n            # contrastive loss\n            dist = F.pairwise_distance(emb1, emb2)\n            loss = (1 - labels) * dist.pow(2) + labels * F.relu(margin - dist).pow(2)\n            loss = loss.mean()\n\n            # --- backward ---\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n\n            # --- accumulate stats ---\n            batch_size = labels.size(0)\n            total_loss += loss.item() * batch_size\n            total_samples += batch_size\n\n            # ðŸŒŸ simple train accuracy (using a fixed threshold on distance)\n            # predict morph(1) if distance > threshold, else bona(0)\n            threshold = margin / 2.0\n            preds = (dist > threshold).float()\n            total_correct += (preds == labels).sum().item()\n\n        avg_loss = total_loss / total_samples\n        train_acc = total_correct / total_samples * 100.0\n\n        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} | Train Acc (approx): {train_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.193747Z","iopub.execute_input":"2025-12-04T03:02:30.193952Z","iopub.status.idle":"2025-12-04T03:02:30.204628Z","shell.execute_reply.started":"2025-12-04T03:02:30.193937Z","shell.execute_reply":"2025-12-04T03:02:30.204057Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"4. Testing Siamese Using Cosine (FRLL)","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass SiameseEmbeddingWrapper(nn.Module):\n    def __init__(self, siamese_model):\n        super().__init__()\n        self.siamese = siamese_model\n\n    def forward(self, x):\n        # x = batch of images\n        # we only want the embedding for one branch\n        return self.siamese.forward_once(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.206933Z","iopub.execute_input":"2025-12-04T03:02:30.207350Z","iopub.status.idle":"2025-12-04T03:02:30.220216Z","shell.execute_reply.started":"2025-12-04T03:02:30.207333Z","shell.execute_reply":"2025-12-04T03:02:30.219574Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# BASELINE 2: ARCFACE + COSINE","metadata":{}},{"cell_type":"code","source":"from facenet_pytorch import InceptionResnetV1\nimport torch.nn as nn\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Create FaceNet embedder\nclass FaceNetEmbedder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n\n    def forward(self, x):\n        x = x.to(device)\n        return self.model(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.220874Z","iopub.execute_input":"2025-12-04T03:02:30.221090Z","iopub.status.idle":"2025-12-04T03:02:30.474418Z","shell.execute_reply.started":"2025-12-04T03:02:30.221067Z","shell.execute_reply":"2025-12-04T03:02:30.473791Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# BASELINE 3: FACENET + COSINE","metadata":{}},{"cell_type":"code","source":"from facenet_pytorch import InceptionResnetV1\n\nfacenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n\nclass FaceNetEmbedder(nn.Module):\n    def forward(self, x):\n        return facenet(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:30.475059Z","iopub.execute_input":"2025-12-04T03:02:30.475340Z","iopub.status.idle":"2025-12-04T03:02:32.292327Z","shell.execute_reply.started":"2025-12-04T03:02:30.475314Z","shell.execute_reply":"2025-12-04T03:02:32.291687Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/107M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e7d42a040de4774a4c17be5a33ab0c3"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from torchvision import transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),      # fixed size = no more mismatch\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),\n    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nfrom torchvision import transforms\ntest_transform = transforms.Compose([\n    transforms.Resize((256, 256)),    # must match training\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:32.293081Z","iopub.execute_input":"2025-12-04T03:02:32.293359Z","iopub.status.idle":"2025-12-04T03:02:32.299274Z","shell.execute_reply.started":"2025-12-04T03:02:32.293333Z","shell.execute_reply":"2025-12-04T03:02:32.298573Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# 1. Load datasets\nfei_train_dataset = DMADDatasetByIndex(\n    csv_path=\"/kaggle/working/FEI_dmad_labels.csv\",\n    img1_idx=0,\n    img2_idx=1,\n    label_idx=2,\n    transform=train_transform,\n    has_header=True\n)\n\nfrll_test_dataset = DMADDatasetByIndex(\n    csv_path=\"/kaggle/working/FRLL_dmad_labels.csv\",\n    img1_idx=0,\n    img2_idx=1,\n    label_idx=2,\n    transform=test_transform,\n    has_header=True\n)\n\n\nfei_train_loader = DataLoader(fei_train_dataset, batch_size=16, shuffle=True)\nfrll_test_loader = DataLoader(frll_test_dataset, batch_size=16, shuffle=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:32.300111Z","iopub.execute_input":"2025-12-04T03:02:32.300345Z","iopub.status.idle":"2025-12-04T03:02:32.346527Z","shell.execute_reply.started":"2025-12-04T03:02:32.300328Z","shell.execute_reply":"2025-12-04T03:02:32.345883Z"}},"outputs":[{"name":"stdout","text":"CSV shape: (10200, 3)\n                                              image1  \\\n0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...   \n\n                                              image2  label  \n0  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n1  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n2  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n3  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \n4  /kaggle/input/face-morph-dsp/FEI_preprocessed/...      0  \nCSV shape: (3705, 3)\n                                              image1  \\\n0  /kaggle/input/face-morph-dsp/FRLL_preprocessed...   \n1  /kaggle/input/face-morph-dsp/FRLL_preprocessed...   \n2  /kaggle/input/face-morph-dsp/FRLL_preprocessed...   \n3  /kaggle/input/face-morph-dsp/FRLL_preprocessed...   \n4  /kaggle/input/face-morph-dsp/FRLL_preprocessed...   \n\n                                              image2  label  \n0  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0  \n1  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0  \n2  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0  \n3  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0  \n4  /kaggle/input/face-morph-dsp/FRLL_preprocessed...      0  \n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"simple_siamese = SimpleSiamese()\ntrain_siamese(simple_siamese, fei_train_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:02:32.347158Z","iopub.execute_input":"2025-12-04T03:02:32.347375Z","iopub.status.idle":"2025-12-04T03:25:19.423037Z","shell.execute_reply.started":"2025-12-04T03:02:32.347359Z","shell.execute_reply":"2025-12-04T03:25:19.422073Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5 - Loss: 0.3324 | Train Acc (approx): 45.91%\nEpoch 2/5 - Loss: 0.3163 | Train Acc (approx): 47.63%\nEpoch 3/5 - Loss: 0.3094 | Train Acc (approx): 47.75%\nEpoch 4/5 - Loss: 0.3071 | Train Acc (approx): 48.19%\nEpoch 5/5 - Loss: 0.3037 | Train Acc (approx): 48.32%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"embed_model = SiameseEmbeddingWrapper(simple_siamese)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:25:19.423926Z","iopub.execute_input":"2025-12-04T03:25:19.424204Z","iopub.status.idle":"2025-12-04T03:25:19.427889Z","shell.execute_reply.started":"2025-12-04T03:25:19.424185Z","shell.execute_reply":"2025-12-04T03:25:19.427309Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"evaluate_cosine_full(embed_model, frll_test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:27:41.364561Z","iopub.execute_input":"2025-12-04T03:27:41.365198Z","iopub.status.idle":"2025-12-04T03:28:34.417630Z","shell.execute_reply.started":"2025-12-04T03:27:41.365176Z","shell.execute_reply":"2025-12-04T03:28:34.416884Z"}},"outputs":[{"name":"stdout","text":"\n==================== COSINE BASELINE RESULTS ====================\nBest Threshold:          0.9799\nAccuracy:                96.73%\nPrecision:               0.9668\nRecall:                  0.9779\nF1-Score:                0.9723\nROC-AUC:                 0.0055\nFAR:                     0.0301\nFRR:                     0.0299\nEER:                     0.0300\nAvg Bona Cosine:         0.9942\nAvg Morph Cosine:        0.9389\n===============================================================\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'threshold': 0.9799498746867168,\n 'accuracy': 0.9673414304993252,\n 'precision': 0.9668181818181818,\n 'recall': 0.9779310344827586,\n 'f1': 0.9723428571428571,\n 'roc_auc': 0.005542483660130712,\n 'far': 0.030065359477124184,\n 'frr': 0.029885057471264354,\n 'eer': 0.02997520847419427,\n 'bona_cos': 0.99416375,\n 'morph_cos': 0.9389273,\n 'all_scores': array([0.972751  , 0.99353206, 0.9995607 , ..., 0.90294385, 0.90323204,\n        0.864683  ], dtype=float32),\n 'all_labels': array([0, 0, 0, ..., 1, 1, 1])}"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"evaluate_cosine_full(FaceNetEmbedder(), frll_test_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T03:28:34.418726Z","iopub.execute_input":"2025-12-04T03:28:34.418940Z","iopub.status.idle":"2025-12-04T03:29:30.911561Z","shell.execute_reply.started":"2025-12-04T03:28:34.418924Z","shell.execute_reply":"2025-12-04T03:29:30.910941Z"}},"outputs":[{"name":"stdout","text":"\n==================== COSINE BASELINE RESULTS ====================\nBest Threshold:          0.7845\nAccuracy:                82.97%\nPrecision:               0.8174\nRecall:                  0.9140\nF1-Score:                0.8630\nROC-AUC:                 0.1005\nFAR:                     0.1876\nFRR:                     0.1899\nEER:                     0.1887\nAvg Bona Cosine:         0.8263\nAvg Morph Cosine:        0.6589\n===============================================================\n\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'threshold': 0.7844611528822054,\n 'accuracy': 0.829689608636977,\n 'precision': 0.8174342105263158,\n 'recall': 0.9140229885057471,\n 'f1': 0.8630345126980681,\n 'roc_auc': 0.10053083915558561,\n 'far': 0.18758169934640523,\n 'frr': 0.18988505747126438,\n 'eer': 0.1887333784088348,\n 'bona_cos': 0.82630235,\n 'morph_cos': 0.6588956,\n 'all_scores': array([0.726274  , 0.86228114, 0.9211072 , ..., 0.67393696, 0.67367387,\n        0.6098199 ], dtype=float32),\n 'all_labels': array([0, 0, 0, ..., 1, 1, 1])}"},"metadata":{}}],"execution_count":23}]}